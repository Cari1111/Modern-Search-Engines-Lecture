{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 4271 - Exercise 4 - Statistical Ranking\n",
    "\n",
    "Issued: May 6, 2025\n",
    "\n",
    "Due: May 12, 2025\n",
    "\n",
    "Please submit this filled sheet via Ilias by the due date.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generative Relevance Models\n",
    "Generative retrieval models use the probabilistic language model framework for matching queries and documents.\n",
    "\n",
    "a) Implement the `rank()` function sketched below. In class, we discussed two alternative model variants. Choose the query likelihood model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.010000000000000002, 'the french bulldog is a small breed of domestic dog'], [0.0, 'the french revolution was a period of upheaval in france'], [0.0, 'french is a very french language spoken by the french']]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#Rank a collection of documents relative to a query using the query likelihood model\n",
    "def rank(Q: str, D: list[str]):\n",
    "     q = Q.lower().split()\n",
    "     lls = []\n",
    "     for d in D:\n",
    "          lls.append([1, d])\n",
    "          counts = Counter(d.lower().split())\n",
    "          for word in set(q):\n",
    "               lls[-1][0] *= (counts[word] / counts.total())\n",
    "     return sorted(lls, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "Q = 'french bulldog'\n",
    "D = ['the french revolution was a period of upheaval in france',\n",
    "     'the french bulldog is a small breed of domestic dog',\n",
    "     'french is a very french language spoken by the french']\n",
    "\n",
    "print(rank(Q, D))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Probabilistic language models may encounter previously unseen query terms. Explain why this can become problematic and how you would address the issue. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability for such a term will be 0 collapsing the whole product/probability in the calculation to 0%. This can be preventend by setting a minimal probability or checking for 0 probs. and ignoring them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Relevance Feedback\n",
    "Relevance Feedback allows us to refine the query representation after a round of user interaction with the search results. If organic feedback is not available, we can assume highly ranked documents to be *pseudo* relevant. Discuss the advantages and disadvantages of the pseudo relevance feedback scheme. Think in particular about single versus multiple rounds of feedback."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each round will improve the results (eventually converging to a local minima) but also cost more time which it being low is critical for user experience."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
